#!/usr/bin/env python3
"""
Cross-chromosome extractor for long-read BAM/CRAM â€” streaming & low-RAM.

This script reads a *name-sorted* alignment file and writes, for each read (query name)
that has at least one supplementary alignment on a different chromosome than its primary,
the primary alignment ONCE and each cross-chrom supplementary alignment ONCE.

Key properties:
- Streams one query-name group at a time -> bounded memory.
- Deduplicates supplementaries per read using a stable key (ref, start, cigar, strand).
- Picks the highest-MAPQ primary if multiple non-secondary, non-supplementary alignments exist.
- Optional: if --keep-all-if-crosschrom, write *all* alignments for that read once any
  cross-chrom supplementary is detected.

Requirements:
- Input must be *name-sorted*. If it's not, run:  samtools sort -n -@ 8 -o name_sorted.bam input.bam
- pysam must be installed.

Example:
    python cross_chrom_streaming.py -i name_sorted.bam -o cross_chrom_only.bam

Author: (generated by ChatGPT)
"""
import argparse
import os
import sys
from typing import List, Tuple, Optional, Iterable, Set

try:
    import pysam  # type: ignore
except ImportError as e:
    sys.stderr.write("ERROR: pysam is required. Install with: pip install pysam\n")
    raise

def is_name_sorted_stream(inp: "pysam.AlignmentFile", check_limit: int = 200000) -> bool:
    """
    Heuristic: verify that query_name is non-decreasing for an initial window of records.
    This avoids holding names in memory. It's not a full proof of contiguity but catches most cases.
    """
    last_qname: Optional[str] = None
    checked = 0
    for rec in inp.fetch(until_eof=True):
        checked += 1
        if last_qname is not None and rec.query_name is not None and rec.query_name < last_qname:
            return False
        last_qname = rec.query_name
        if checked >= check_limit:
            break
    inp.reset()
    return True

def group_by_qname(inp: "pysam.AlignmentFile") -> Iterable[List["pysam.AlignedSegment"]]:
    """
    Yield lists of records that share the same query_name. Requires name-sorted input.
    """
    current_name: Optional[str] = None
    group: List["pysam.AlignedSegment"] = []
    for r in inp.fetch(until_eof=True):
        qn = r.query_name
        if current_name is None:
            current_name = qn
        if qn != current_name:
            yield group
            group = [r]
            current_name = qn
        else:
            group.append(r)
    if group:
        yield group

def pick_primary(primaries: List["pysam.AlignedSegment"]) -> Optional["pysam.AlignedSegment"]:
    """
    Pick the primary with highest MAPQ. If tie, take the first encountered.
    """
    if not primaries:
        return None
    best = primaries[0]
    best_mapq = getattr(best, "mapping_quality", 0)
    for r in primaries[1:]:
        mq = getattr(r, "mapping_quality", 0)
        if mq > best_mapq:
            best = r
            best_mapq = mq
    return best

def stable_key(r: "pysam.AlignedSegment") -> Tuple[int, int, str, bool, bool]:
    """
    Create a stable key to deduplicate identical alignments in the same group.
    (reference_id, reference_start, cigarstring, is_reverse, is_supplementary)
    """
    return (r.reference_id if r.reference_id is not None else -1,
            r.reference_start if r.reference_start is not None else -1,
            r.cigarstring or "",
            bool(r.is_reverse),
            bool(r.is_supplementary))

def write_group(
    reads: List["pysam.AlignedSegment"],
    out: "pysam.AlignmentFile",
    keep_all_if_crosschrom: bool = False
) -> int:
    """
    Write records for a single query-name group according to the rules.
    Returns number of records written.
    """
    if not reads:
        return 0

    # Separate categories
    primaries = [r for r in reads if not r.is_secondary and not r.is_supplementary]
    supps     = [r for r in reads if not r.is_secondary and r.is_supplementary]

    # Choose a primary
    primary = pick_primary(primaries)
    if primary is None or primary.reference_id is None or primary.reference_id < 0:
        return 0  # nothing to do without a mapped primary

    # Check for cross-chrom supplementaries
    cross = [s for s in supps if s.reference_id is not None and s.reference_id >= 0 and s.reference_id != primary.reference_id]
    if not cross:
        return 0

    written = 0
    seen: Set[Tuple[int, int, str, bool, bool]] = set()

    if keep_all_if_crosschrom:
        # Write all alignments for this read (primary + any supps/secondaries) once cross-chrom is detected.
        for r in reads:
            k = stable_key(r)
            if k not in seen:
                out.write(r)
                seen.add(k)
                written += 1
        return written

    # Default behavior: write primary ONCE, and each cross-chrom supplementary ONCE
    for r in [primary] + cross:
        k = stable_key(r)
        if k not in seen:
            out.write(r)
            seen.add(k)
            written += 1
    return written

def parse_args(argv: Optional[List[str]] = None) -> argparse.Namespace:
    p = argparse.ArgumentParser(
        description="Extract cross-chromosome supplementary alignments from a name-sorted long-read BAM/CRAM, streaming to keep RAM low."
    )
    p.add_argument("-i", "--input", required=True, help="Name-sorted input alignment (BAM/CRAM/SAM).")
    p.add_argument("-o", "--output", required=True, help="Output BAM/CRAM/SAM (different path from input).")
    p.add_argument("--reference", help="Path to reference FASTA (required if writing CRAM).")
    p.add_argument("--keep-all-if-crosschrom", action="store_true",
                   help="If set, write ALL alignments for a read once a cross-chrom supplementary is detected.")
    p.add_argument("--no-namesort-check", action="store_true",
                   help="Skip the initial heuristic name-sort check (faster, but riskier).")
    return p.parse_args(argv)

def main(argv: Optional[List[str]] = None) -> int:
    args = parse_args(argv)

    inpath = args.input
    outpath = args.output

    if not os.path.exists(inpath):
        sys.stderr.write(f"ERROR: input path does not exist: {inpath}\n")
        return 2
    if os.path.abspath(inpath) == os.path.abspath(outpath):
        sys.stderr.write("ERROR: output path must be different from input path.\n")
        return 2

    # Open input
    try:
        in_mode = "r"
        low = inpath.lower()
        if low.endswith(".bam"):
            in_mode = "rb"
        elif low.endswith(".cram"):
            in_mode = "rc"
        inp = pysam.AlignmentFile(inpath, in_mode)
    except Exception as e:
        sys.stderr.write(f"ERROR: failed to open input {inpath}: {e}\n")
        return 2

    # Optional quick check for name-sortedness
    import re

    _digit_re = re.compile(r'(\d+)')

    def natural_key(s: str):
        return tuple(int(t) if t.isdigit() else t for t in _digit_re.split(s))

    def is_name_sorted_stream(inp, check_limit: int = 200000) -> bool:
        last_key = None
        checked = 0
        for rec in inp.fetch(until_eof=True):
            checked += 1
            qn = rec.query_name or ""
            key = natural_key(qn)
            if last_key is not None and key < last_key:
                return False
            last_key = key
            if checked >= check_limit:
                break
        inp.reset()
        return True

    # Prepare output with same header
    try:
        # Detect output mode from extension
        mode = "wb"
        if outpath.lower().endswith(".sam"):
            mode = "w"
        elif outpath.lower().endswith(".cram"):
            mode = "wc"
        # When writing CRAM, a reference is recommended/required
        out_kwargs = {}
        if mode == "wc":
            if not args.reference:
                sys.stderr.write("WARNING: writing CRAM without --reference may fail or produce large files.\n")
            else:
                out_kwargs["reference_filename"] = args.reference
        out = pysam.AlignmentFile(outpath, mode, header=inp.header, **out_kwargs)
    except Exception as e:
        inp.close()
        sys.stderr.write(f"ERROR: failed to open output {outpath}: {e}\n")
        return 2

    # Stream groups and write
    total_groups = 0
    total_written = 0
    try:
        for grp in group_by_qname(inp):
            total_groups += 1
            total_written += write_group(grp, out, keep_all_if_crosschrom=args.keep_all_if_crosschrom)
    finally:
        inp.close()
        out.close()

    sys.stderr.write(f"Done. Processed {total_groups} read groups; wrote {total_written} records to {outpath}.\n")
    return 0

if __name__ == "__main__":
    sys.exit(main())
